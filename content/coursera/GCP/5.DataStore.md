---
title: "5. Cloud DataStore Concepts and Indexes"
date: 2019-03-16T11:34:29+09:00
Categories: ["Google Cloud Service"]
Tags: ["Coursera", "Google Cloud Service"]
Author: "nolleh"
---

# Cloud Datastore Concepts and Indexes

---

## Cloud Data Store concepts

- 데이터 오브젝트는 엔터티라고 불림
- 엔터티들은 하나이상의 프로퍼티로 구성됨
- 프로퍼티들은 하나이상의 값(values) 를 가질수 있음
- 각각의 엔터티는 구분되는 하나의 키를 가지고 있는데, 다음으로 구성 된다.
  - 네임스페이스
  - 엔터티 Kind
  - 식별자 (스트링 or 숫자)
  - 부모 ID
- 하나 이상의 엔터티에 대한 동작은 트랜잭션으로 불린다.

## Datastore has two types of indexes

| Built-in indexes                                          | Composite indexes                                    |
| --------------------------------------------------------- | ---------------------------------------------------- |
| 각각의 엔터티 Kind의 각각의 프로퍼티에 대해 자동으로 정의 | 인덱싱된 엔터티에 대해 다중의 프로퍼티 값을 인덱스함 |
| 간단한 쿼리에 적합                                        | 컴플렉스 쿼리에 적합                                 |
|                                                           | 인덱스 설정파일에 정의                               |

| concept                            | cloud datastore | relational database |
| ---------------------------------- | --------------- | ------------------- |
| 오브젝트 카테고리                  | Kind            | Table               |
| 한개 오브젝트                      | entity          | row                 |
| 하나의 오브젝트를 위한 개별 데이터 | 프로퍼티        | field               |
| 유니크 ID                          | Key             | PrimaryKey          |

# Design Considerations & Sharding

---

## Design Your application for scale

- 엔터티 그룹에 대한 최대 쓰기율은 1/초
- 사전적으로 가까운 키에 대한 읽기와 쓰기를 너무 자주하지 말것.
  구글의 noSQL 데이터베이스 Bigtable 을 이용해서 구현되어있는데
  확장할때 로우들을 별도 테이블로 샤딩하는데 이 로우들이
  키에 대해 사전적으로 정렬되어있기 때문.
- 점진적으로 ramp up traffic 을 새로운 클라우드 데이터 스토어에..
  빅테이블이 테이블을 분리하기에 충분할 시간을 주도록..
- 클라우드 데이터스토어의 엔터티를 적은 범위의 키로 삭제하는 동작을 피해라
  컴팩션(삭제된 엔트리를 제거하고 데이터를 재구성하여 읽기와 쓰기가 더 효율적으로 동작하도록 주기적으로 테이블을 다시쓰는 작업) 타임스탬프가 비슷해서 함께 있을 엔터티들을 많이 삭제하면, 이에 대한 쿼리가 컴팩션이 완료되기 전까지 늦을 수 있다.
- 핫 클라우드 데이터 스토어 키들에 대해 :
  - use sharding, 쓰기가 빈번한 키 range 에.
  - use replication, 읽기가 빈번한 키 range.

## When sharding, remember:

- 트랜잭션 스루풋은 1 write/sec per entity group
- 복수의 kinds 에 걸쳐 자주 업데이트 되는 엔터티는 분리하라.

## Shared counters to avoid contention with high writes

contention 을 줄이기 위해:

- sharded counter 를 구축하라 (카운터를 N 개의 다른 카운터로 쪼개라) - 카운터를 올리기 위해 임의의 샤드를 선택하여 올린다 - 전체 카운트를 알기위해, 모든 샤드카운터를 읽어서 더해라.
  샤드의 넘버를 올리는 것은 스루풋을 올리는 것..
  increasing the number of shards will increase the throughput you will have for increments on you counter.

# Replicaion, Query Types, Transactions, and Handling Errors

---

## Use replication to read a portion of the key range

읽기 비율이 높은데에 사용.
엔터티에 대한 사본을 N 개에 대해 두면, 읽기 연산에 대해 N 배 빠르다.

Devices -> Cloud Load Balance -> Front end App (AppEngine - auto scailiing)

## Use qurey types based on your needs

1. Keys-only
2. Projection (엔터티에서 프로퍼티를 얻어옴.)
3. Ancester - 쿼리의 강한 일관성을 요할때.
   select \* from task where `__key__` has ancestor key(TaskList, 'default')
4. Entity
   select \* from task where done = FALSE

## Improve Your query latency by using cursors instead of offsets

# Demo: Use Cloud Dataflow to bulk-load data into Cloud data store

---

pip install apache-beam

# lab

git clone https://github.com/GoogleCloudPlatform/training-data-analyst

# Summary

조상을 지정하는 것으로 엔터티 그룹을 설정할수 있다.  
이렇게 해서 모든 관계된 엔터티들이 하나의 트랜잭션으로 업데이트 될 수 있다.
트래픽 램프업을 위해 555 룰을 따라라.
처음엔 초당 500 정도를 쓰다가 5분마다 50퍼센트씩 증가 시키는 것.
